# Risques et abus

import { Callout } from 'nextra-theme-docs' [ A supprimzr ?]

Nous avons déjà vu à quel point des prompts bien conçus peuvent être efficaces pour diverses tâches à l'aide de techniques telles que l'apprentissage few-shot [TO DO] et le chain-of-though prompting [TO DO]. Alors que nous envisageons de construire des applications du monde réel [A revoir] à partir des LLMs, il devient crucial de réfléchir aux abus, aux risques et aux pratiques de sécurité impliqués dans les modèles de langage.[A reformuler]

Cette section se concentre sur la mise en évidence de certains risques et abus des LLMs par le biais de techniques telles que les injections [TO DO] de prompt. Elle met également en évidence les comportements nuisibles et la manière de les atténuer potentiellement grâce à des techniques de prompting efficaces. D'autres sujets d'intérêt incluent la généralisabilité [TO DO], l'étalonnage, les biais, les biais sociaux et la factualité [TO DO fiabilité?] , pour n'en citer que quelques-uns.

<Callout emoji="⚠️">
  Cette section est en plein développement.
</Callout>
