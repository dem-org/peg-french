# Active-Prompt

import { Callout, FileTree } from 'nextra-theme-docs'
import {Screenshot} from 'components/screenshot'
import ACTIVE from '../../img/active-prompt.png'

Les méthodes de chain-of-thought (CoT) s'appuient sur un ensemble fixe d'exemples annotés par l'homme. Le problème est que les exemples peuvent ne pas être les plus efficaces pour les différentes tâches. Pour y remédier, [Diao et al., (2023)] (https://arxiv.org/pdf/2302.12246.pdf) ont récemment proposé une nouvelle approche de prompt appelée active-prompt (TODO) pour adapter les LLMs à différentes tâches spécifiques d'exemples de prompts (annotés avec un raisonnement CoT conçu par l'homme).


L'approche est illustrée ci-dessous. La première étape consiste à interroger le LLM avec ou sans quelques exemples CoT. *k* réponses possibles sont générées pour un ensemble de questions d'entraînement. Une mesure d'incertitude est calculée sur la base des *k* réponses (désaccord utilisé). Les questions les plus incertaines sont sélectionnées pour être annotées par des humains. Les nouveaux exemples annotés sont ensuite utilisés pour déduire chaque question. 

<Screenshot src={ACTIVE} alt="ACTIVE" />
Source de l'image : [Diao et al., (2023)] (https://arxiv.org/pdf/2302.12246.pdf)
